<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.31.1" />
  <meta name="author" content="董雷鸣Leiming Dong">
  <meta name="description" content="PhD">

  
  <link rel="alternate" hreflang="en-us" href="../../post/a-gentle-inla-tutorial/">

  
  


  

  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="../../styles.css">
  

  

  
  <link rel="alternate" href="../../index.xml" type="application/rss+xml" title="Enterprising &amp; Concentrating">
  <link rel="feed" href="../../index.xml" type="application/rss+xml" title="Enterprising &amp; Concentrating">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="../../post/a-gentle-inla-tutorial/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@donglm2008">
  <meta property="twitter:creator" content="@donglm2008">
  
  <meta property="og:site_name" content="Enterprising &amp; Concentrating">
  <meta property="og:url" content="/post/a-gentle-inla-tutorial/">
  <meta property="og:title" content="INLA教程|A gentle INLA tutorial | Enterprising &amp; Concentrating">
  <meta property="og:description" content="">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-01-02T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-01-02T00:00:00&#43;00:00">
  

  

  <title>INLA教程|A gentle INLA tutorial | Enterprising &amp; Concentrating</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../../"><img src="../../img/dong_logo.png" alt="Enterprising &amp; Concentrating"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="../../#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">INLA教程|A gentle INLA tutorial</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2018-01-02 00:00:00 &#43;0000 UTC" itemprop="datePublished dateModified">
      Jan 2, 2018
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="董雷鸣Leiming Dong">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="../../post/a-gentle-inla-tutorial/#disqus_thread"></a>
  

  
  
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=INLA%e6%95%99%e7%a8%8b%7cA%20gentle%20INLA%20tutorial&amp;url=%2fpost%2fa-gentle-inla-tutorial%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fa-gentle-inla-tutorial%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fa-gentle-inla-tutorial%2f&amp;title=INLA%e6%95%99%e7%a8%8b%7cA%20gentle%20INLA%20tutorial"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fa-gentle-inla-tutorial%2f&amp;title=INLA%e6%95%99%e7%a8%8b%7cA%20gentle%20INLA%20tutorial"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=INLA%e6%95%99%e7%a8%8b%7cA%20gentle%20INLA%20tutorial&amp;body=%2fpost%2fa-gentle-inla-tutorial%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        <blockquote>
<p>本文翻译自<a href="https://www.precision-analytics.ca/blog-1/inla">A gentle INLA tutorial</a>，作者Kathryn Morrison，Google &amp; Leiming Dong 翻译。</p>
</blockquote>
<p>INLA是替代MCMC拟合贝叶斯模型的一个很好的（快速）方案。这两种方法各有优缺点：MCMC是非常直观的方法，甚至在简单的情况下你自己就能实现；INLA算法对我来说是数学的延伸。</p>
<p>我觉得现在好多了，但是当我第一次学习INLA的论文的时候，并没有多少介绍。我在博士学位上花费了好几个月的时间，仔细研究INLA论文中的证明试图理解这一切。</p>
<p>为了我自己的好处，我为应用统计学家做了一个总结 - 像我这样的人，对正态分布、泰勒级数展开和贝叶斯定理等理论已经足够熟悉，但是可能没有花很多时间在最近的Hessian上。</p>
<p>有一个非常简单的解释。如果你对更的理解感兴趣，那么开创性的论文是非常彻底和清晰的，值得一读（或读五十遍）。细节是有趣和重要的。但是，我的目的是给你一些要点，这是我开始时所希望的。</p>
<div id="inla" class="section level1">
<h1>简介：为什么选择INLA</h1>
<p><strong>分层模型</strong>广泛用于多学科，表示数据中复杂的依赖结构。模型参数和潜在变量或过程中的不确定性可以在贝叶斯框架中使用适当的先验分布进行编码。</p>
<p>虽然后验分布几乎没有封闭形式的解，但是通过<strong>马尔可夫链蒙特卡洛（MCMC）</strong>方法的广义解已经被开发成WinBUGS之类的软件。MCMC速度慢，不能很好地扩展，对于一些复杂的模型可能会失败（模型不会收敛）。较新的软件（JAGS，Stan）试图解决这些问题。</p>
<p>MCMC是一种渐近确切的方法，INLA则是一种近似。有时使用INLA会遇到怀疑或问题，例如“但近似误差怎么样？您的结果有多自信？”有些时候INLA会失败，但最好记住我们不住在asymptopia中。从经验上讲，MCMC误差和INLA误差常常非常相似，正如许多模拟研究所显示的那样，而且我自己也多次观察到。</p>
<p>对于<strong>潜在高斯模型（LGM）</strong>的一般类别，INLA是MCMC的快速替代方案。许多熟悉的模型可以被重新塑造成LGM，比如GLM（M）、GAM（M）、时间序列、空间模型、测量误差模型等等。</p>
<div class="alert alert-warning">
  <p>要了解INLA那里的要点，我们需要熟悉：</p>

</div>

<p>1.贝叶斯推理 2.潜在高斯模型（LGM） 3.高斯马尔科夫随机场（GMRF） 4.拉普拉斯近似</p>
<p>如果您有兴趣了解INLA，那么我认为您已经熟悉贝叶斯推理，但是我们将从一个非常简短的回顾开始。</p>
</div>
<div class="section level1">
<h1>1.贝叶斯推理</h1>
<p>在贝叶斯模型中，我们通常想要得到模型的后验分布（例如给定数据的参数分布）或预测后验分布（预测/预测 - 观察到的新值的分布）。让我们把重点放在前一种情况，然后是后者。</p>
<p><strong>后验分布等于数据可能性乘以标准化常数的先验值（所以后验积分为1）。</strong></p>
<p><span class="math display">\[p(\theta | y) = \frac{p(y|\theta) p(\theta)} {\int p(y|\theta) p(\theta)d\theta} \propto  p(y|\theta) p(\theta) \]</span></p>
<p><strong>在一个频率学派框架中，我们经常使用像Newton-Raphson这样的数值方法来最大化数据可能性，以获得给定参数（我们认为是固定的但是未知的）的点估计，并且使用理论重采样的思想来估计围绕该参数估计相应的置信区间。</strong>实际上，我们经常使用bootstrapping形式的显式重采样，但这是另一回事。在贝叶斯分析中，我们获得参数的后验分布（我们将其视为一个随机变量），为此我们可以提供汇总统计（中位数，中位数或模式）和分位数来直接获得可靠的区间。</p>
<p>如果我们对每个参数使用共轭先验（使数学容易的规范分布的种类），那么我们可能能够确定闭合形式的后验分布。通常，<strong>分母中的积分是难以处理的，所以我们使用MCMC等数值方法从条件中进行抽样，并估计每个感兴趣的参数的边际分布</strong>。</p>
</div>
<div class="section level1">
<h1>2.潜在的高斯模型</h1>
<p>LGM的一般形式是：</p>
<p><span class="math inline">\(\mathbf{y} | \mathbf{x}, \mathbf{\theta_2} \sim \prod_i \ p(y_i | \eta_i, \mathbf{\theta_2})\)</span> “Likelihood”</p>
<p><span class="math inline">\(\mathbf{x} | \mathbf{\theta_1} \sim p(\mathbf{x}|\mathbf{\theta_1}) = \mathcal{N}(0,\mathbf{\Sigma})\)</span> “Latent field”</p>
<p><span class="math inline">\(\mathbf{{\theta}} = [\mathbf{\theta_1},\mathbf{\theta_2}]^T \sim p(\mathbf{\theta})\)</span> “Hyperpriors”</p>
<p>哪里<span class="math inline">\(\mathbf{y}\)</span>是一个观察数据集， <span class="math inline">\(\mathbf{x}\)</span> 不是协变量，而是线性预测变量（包括它本身）中所有参数的联合分布，<span class="math inline">\(\mathbf{\theta}\)</span>是潜在域的超参数，不是高斯。</p>
<p>我们熟悉的模型，比如前面提到的GLM（M）如何适合这个框架？那么，考虑一个广义（线性/加法）（混合）模型的一般形式：</p>
<p><span class="math display">\[ \mathbf{y} \sim \prod_i^N p(y_i | \mu_i)\]</span> <span class="math display">\[ g(\mu_i) = \eta_i = \alpha + \sum_{k=1}^{n_\beta} \beta_k z_{ki}  + \sum_{j=1}^{n_f} f^{(j)}(w_{ji}) + \varepsilon_i \]</span></p>
<p><span class="math inline">\(g(\cdot)\)</span>是链接函数， <span class="math inline">\(\alpha\)</span>是截距， <span class="math inline">\(\mathbf{\beta}\)</span>是（线性的）协变量的熟悉的回归参数<span class="math inline">\(\mathbf{z}\)</span>，<span class="math inline">\(\mathbf{f} = f_1(\cdot), f_2(\cdot), ..., f_{n_\beta}(\cdot)\)</span>是一些协变量 <span class="math inline">\(\mathbf{w}\)</span>的一组函数，协变量可能是非线性的，比如随机（<span class="math inline">\(iid\)</span>）效应，空间或时间相关效应，平滑样条等。</p>
<p>线性回归是一个特殊情况，其结果是高斯，链接函数是identity， <span class="math inline">\({\mathbf{f}}(.)\)</span> = 0。在传统的BYM空间模型中， <span class="math inline">\(f_1(\cdot) \sim CAR\)</span>和<span class="math inline">\(f_2(\cdot) \sim N(0, \sigma^2_{f_2})\)</span>，及链接函数通常是 <em>logit</em> 或 <em>log</em> ，因为你经常有一个二项或泊松结果变量。许多熟悉的模型是这种最一般形式的特例（比其他更明显）。</p>
<p>这个模型是一个LGM <span class="math inline">\(iff\)</span>我们假设这些参数具有联合的高斯分布。这可以通过在每个参数上设置普通的先验来实现）：</p>
<p><span class="math display">\[\mathbf{x} = [\mathbf{\eta}, \alpha, \mathbf{\beta}, \mathbf{f}(\cdot)] \sim \mathcal{N}(0, \mathbf{\Sigma}) \]</span></p>
<p>如果我们可以假设<span class="math inline">\(\mathbf{x}\)</span>中条件独立，那么这个潜在场 <span class="math inline">\(\mathbf{x}\)</span>是一个高斯马尔科夫随机场。在令人惊讶的很多情况下，这个假设是合理的。当我在下一节介绍GMRF时，我将讨论更多。这里需要注意的是维度的重要性<span class="math inline">\(\mathbf{x}\)</span> 通常是很大的，因为它通过线性预测器与数据成比例，而非高斯超参数<span class="math inline">\(\mathbf{\theta}\)</span>一般很小。</p>
</div>
<div class="section level1">
<h1>3.高斯马尔可夫随机场</h1>
<p>GMRF是一个随机向量，遵循具有马尔可夫性质的多元正态分布：例如<span class="math inline">\(i\neq j\)</span>, <span class="math inline">\(x_i \perp x_j | \mathbf{x}_{-ij}\)</span>。“<span class="math inline">\(-ij\)</span>”是指“除了”<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>之外的所有元素。考虑（空间或时间）自回归过程作为这个马尔可夫性质的一个自然的例子。</p>
<p>回想一下，<strong>精度是方差的逆</strong>。同样，精度矩阵（<span class="math inline">\(\mathbf{Q}\)</span>）是其对应的协方差矩阵的逆（<span class="math inline">\(\mathbf{\Sigma}\)</span>），例如， <span class="math inline">\(\mathbf{x} \sim \mathcal{N}(0,\mathbf{\Sigma}), \mathbf{Q} = \mathbf{\Sigma}^{-1}\)</span>。还记得在重要情况下，对矩阵求逆是一个复杂且计算密集的操作，<span class="math inline">\(\mathcal{O}(n^3)\)</span>。</p>
<p>稀疏矩阵（有很多零）更容易求逆。例如，一个对角矩阵是稀疏的，很容易求逆（实际上是元素的逆），单位矩阵是它自己的逆矩阵：<span class="math inline">\(I^{-1} = I\)</span>。但是，即使一些非对角元素是非零的，零也会大大提升计算。</p>
<p>我们已经知道以下结果：</p>
<p><span class="math display">\[ x_i \perp x_j  \Leftrightarrow \mathbf{\Sigma}_{ij} = 0 \]</span></p>
<p>因此，如果我们想要获得稀疏的协方差矩阵，我们将不得不假设参数之间有很大的<strong>边际独立性</strong>，这是一个强大而且通常不合理的假设。然而，条件独立性（通过马尔可夫性）往往是一个非常合理的假设。GMRF方法的威力来自Havard Rue et al显示了条件独立特性是如何在精度矩阵中编码的，以及如何利用这些特性来改进涉及这些矩阵的计算。经过大量的工作，可以看出：</p>
<p><span class="math display">\[ x_i \perp x_j | \mathbf{x}_{-ij} \Leftrightarrow \mathbf{Q}_{ij} = 0 \]</span></p>
<p>因此，GMRF中的马尔可夫假设产生了一个稀疏精度矩阵。这个稀疏被转化为Cholesky分解矩阵（<span class="math inline">\(\mathbf{Q}=\mathbf{LL}^T\)</span>）并且帮助极快的计算。由于这是大矩阵，所以它是计算最重要的一个。</p>
</div>
<div class="section level1">
<h1>4.拉普拉斯近似</h1>
<p>回想一下基本的泰勒级数展开式，其中有关于某一点<span class="math inline">\(a\)</span>的函数 可以扩展成（有时是无限的）项的和，并且使用有限数量的这些项可以用作近似（通常使用前三个项，直到二阶导数）。</p>
<p><span class="math display">\[f(x) = f(a) + \frac{f&#39;(a)}{1!}(x-a) +  \frac{f&#39;&#39;(a)}{2!}(x-a)^2 +  \frac{f&#39;&#39;&#39;(a)}{3!}(x-a)^3 + ...\]</span></p>
<p>我们有基本的抛物线， <span class="math inline">\(y = x^2\)</span>。围绕a=2展开（这里我们可以选择任何值）：</p>
<p><span class="math display">\[f(x) = x^2 \hspace{7mm} f&#39;(x) = 2x, \hspace{7mm} f&#39;&#39;(x) = 2, \hspace{7mm} f&#39;&#39;&#39;(x) = 0 
\]</span></p>
<p>因此：</p>
<p><span class="math display">\[f(x) = x^2 = 2^2 + 2(2)(x-2) + \frac{2}{2}(x-2)^2 \]</span></p>
<p>{{&lt; figure src=“/img/taylor.png” title=“taylor” &gt;}}</p>
<p>拉普拉斯近似用于估计具有正态分布的任何分布（PDF）。它使用前三项（二次函数）泰勒级数展开模式(<span class="math inline">\(\hat{x}\)</span>)的函数来近似<span class="math inline">\(\log g(x)\)</span>（log简化了微分）：</p>
<p><span class="math display">\[\log g(x) \approx \log g(\hat{x}) + \frac{\partial \log g(\hat{x})} {\partial x} (x-\hat{x}) +  \frac{\partial^2 \log g(\hat{x})} {2 \partial x^2} (x-\hat{x})^2\]</span></p>
<p>模式中的一阶导数为零，所以上面的表达式简化了，如果我们说估计的方差（基于曲率）是 $^2 = -1 /  $，那么我们可以重写这些表达式为：</p>
<p><span class="math display">\[\log g(x) \approx \log g(\hat{x}) - \frac{1}{2\sigma^2} (x-\hat{x})^2\]</span></p>
<p>希望开始看起来很熟悉！我们可以用这个结果做一个正常的近似。以双边的指数和积分取出常数：</p>
<p><span class="math display">\[\int g(x)dx = \int exp[\log g(x) dx] \approx constant \int exp[ - \frac{(x-\hat{x})^2}{2\hat{\sigma^2}}]dx\]</span></p>
<p>使用拉普拉斯近似的分布<span class="math inline">\(f(x)\)</span>与平均值近似正常<span class="math inline">\(\hat{x}\)</span>这可以在模式下通过解<span class="math inline">\(f&#39;(x) = 0\)</span>及方差<span class="math inline">\(\hat{\sigma}^2 = -1/f&#39;&#39;(x)\)</span>找到 。不太相信？以下是一个简单的例子<span class="math inline">\(\chi^2\)</span> （因为很容易用手区分;分母中的伽马项只是常数）。 <span class="math display">\[
\begin{align*}
f(x;\,k) &amp;=
  \frac{x^{(k/2-1)} e^{-x/2}}{2^{k/2} \Gamma\left(\frac{k}{2}\right)},   x \geq 0 \\
\log f(x) &amp;= (k/2 - 1) \log x - x/2  \\
\log f&#39;(x) &amp;= (k/2 -1)/x - 1/2 = 0   \\
\log f&#39;&#39;(x) &amp;= -(k/2 - 1)/x^2  \\
\therefore \chi^2_k    &amp;\overset{LA}{\sim}  N(\hat{x} = k-2, \hat{\sigma}^2 = 2(k-2))
\end{align*} 
\]</span></p>
<p>{{&lt; figure src=“/img/approximation.png” title=“approximation” &gt;}}</p>
<p>当自由度更高时（当分布更接近正常时），逼近显然更好。这是一个非常简单的单变量的例子，但重要的是要说服你，当事情大致正常时，这往往运作良好。它可以延伸到多元的情况，就像你所期望的一样，使用Hessian曲率，大量的数学运算发生。</p>
</div>
<div class="section level1">
<h1>把它们放在一起：集成的嵌套拉普拉斯近似</h1>
<p>我们只是覆盖了很多不同的部分，但是我们从LGM中需要的是潜在场的元素的边界（例如回归参数）以及可能来自超前分布的一些元素（例如，自回归模型中的相关参数，或随机效应的方差）——我们想要拟合分层模型！</p>
<p><span class="math display">\[p(x_j | \mathbf{y}) = \int p(x_j, \mathbf{\theta} | \mathbf{y}) d\mathbf{\theta}  = \int p(x_j | \mathbf{\theta},\mathbf{y}) p(\mathbf{\theta} | \mathbf{y})  d\mathbf{\theta}\]</span></p>
<p><span class="math display">\[p(\theta_k | \mathbf{y}) = \int p(\mathbf{\theta}|\mathbf{y}) d\mathbf{\theta}_{-k}\]</span></p>
<p>因此，我们需要近似的项是： <span class="math inline">\(p(\mathbf{\theta}|\mathbf{y})\)</span>和<span class="math inline">\(p(x_j | \mathbf{\theta}, \mathbf{y})\)</span>。第一项可以用来估计所有感兴趣的边际<span class="math inline">\(\mathbf{\theta}\)</span>，也需要估计潜在场的边际。从概率回忆：</p>
<p><span class="math display">\[
\begin{align}
p(b) &amp;= \frac{p(a,b)} {p(a|b)} \\
p(b|c) &amp;= \frac{p(a,b|c)} {p(a|b,c)} 
\end{align} 
\]</span></p>
<p>我们可以用这个规则来重写我们的边际分布：</p>
<p><span class="math display">\[
\begin{align}
p(\mathbf{\theta} | \mathbf{y}) &amp;= \frac{p(\mathbf{x}, \mathbf{\theta} \mathbf{|} \mathbf{y})} {p(\mathbf{x} \mathbf{|} \mathbf{\theta}, \mathbf{y}) } \nonumber 
 \end{align} 
\]</span></p>
<p>我们可以扩大分子（细节略），并使用拉普拉斯近似为分母，这是未知的：</p>
<p><span class="math display">\[ 
\begin{align}
p(\mathbf{\theta} | \mathbf{y}) &amp;\approx \frac{p(\mathbf{y|x,\theta}) p(\mathbf{x|\theta})p(\mathbf{\theta})} {\tilde{p}(\mathbf{x|\theta,y})} \bigg|_{x={x^*}(\theta)}  = \tilde{p}(\mathbf{\theta|y}) 
\end{align} 
\]</span></p>
<p><span class="math inline">\(x^*(\theta)\)</span> 是的模式<span class="math inline">\(\mathbf{x}\)</span>对于给定的配置<span class="math inline">\(\mathbf{\theta}\)</span>。获取<span class="math inline">\(p(x_j | \mathbf{\theta}, \mathbf{y})\)</span>使用相同的逻辑，但是因为维数更复杂 <span class="math inline">\(\mathbf{x}\)</span>更大。</p>
<p>最明显的选择是直接使用一个正常的近似值<span class="math inline">\(p(x_j|\mathbf{\theta},\mathbf{y})\)</span>，因为我们已经在上面的分母中计算了这一点。这是非常快的，但假设太强大，结果往往很差（这些条件分布常常有些偏斜或重尾）。或者，我们可以划分<span class="math inline">\(\mathbf{x} = [x_j, \mathbf{x}_{-j}]\)</span>并使用拉普拉斯近似来表示潜在场中的每个元素<span class="math inline">\(\mathbf{x}\)</span>：</p>
<p><span class="math display">\[
\begin{align}
p(x_j | \mathbf{\theta,y}) \propto \frac{p(\mathbf{x,\theta |y})}{p(\mathbf{x}_{-j} | x_j, \mathbf{\theta, y})} \propto \frac{p(\mathbf{\theta})p(\mathbf{x|\theta})p(\mathbf{y|x})}{p(\mathbf{x}_{-j} | x_j, \mathbf{\theta, y})}  
\end{align} 
\]</span></p>
<p>这种方法工作得很好，因为条件<span class="math inline">\(p(\mathbf{x_{-j}} | x_j, \mathbf{\theta, y})\)</span>往往接近正常，但在计算上更昂贵。</p>
<p>第三个选项（默认在INLA软件中）使用简化的拉普拉斯近似（两者之间的折衷），这在计算上是非常有效的，并且近似值仍然非常好。它使用一个泰勒级数展开直到分子和分母的三阶来估计<span class="math inline">\(p(x_j|\mathbf{\theta,y})\)</span>。</p>
<p>其他两种选择都可以在INLA中使用。我个人将这些模型与近似值进行拟合，因为它非常快。结果大概是一样的，但是和使用MCMC（或者如果你正在做一个模拟的话）是不一样的。所以我做了一些基本的构建和近似验证，然后使用简化的或完整的Laplace作为最终的模型。我从来没有亲自观察过可以在简化和完全拉普拉斯之间进行有意义区分的场景。</p>
<p>INLA算法使用类似牛顿的方法来探索超参数的联合后验分布<span class="math inline">\(\tilde{p}(\mathbf{\theta|y})\)</span>为数值积分寻找合适的点：</p>
<p><span class="math display">\[
\begin{align*} 
\tilde{p}(x_j|\mathbf{y}) \approx \sum_{h=1}^H \tilde{p}(x_j | \theta^*_h,\mathbf{y}) \tilde{p}(\theta^*_h|\mathbf{y}) \Delta_h
\end{align*}
\]</span></p>
<p>现在我们可以得到INLA正在做的事情的要点！</p>
<p><strong>积分</strong>：使用数值积分</p>
<p><strong>嵌套</strong>：因为我们需要<span class="math inline">\(p(\mathbf{\theta | y)}\)</span>得到<span class="math inline">\(p(x_j | \mathbf{y})\)</span></p>
<p><strong>拉普拉斯近似</strong>：用于获得正态近似参数的方法</p>
<p>Finn Lindgren等人在2011年的研究中提出了一种INLA的随机偏微分方程（SPDE）方法，允许在点数据表面具有曲率的大地理区域进行更真实的空间建模，从而实现连续的协方差函数。我今天不会讨论这个，但是可能会在SPDE上做一个未来的帖子。如果您刚刚开始了解INLA，除非SPDE是您感兴趣的唯一部分，否则我会建议先学习基础知识。随机微积分不是我们中间大多数每天使用的应用类型。</p>
<p>我知道有很多的信息——但实际上我几乎没有抓到表面！我建议查看2009年的原始INLA论文（参见参考文献）。现在，让我们看看R-INLA代码长什么样样子，以及在一些简单的例子中，如何使用MCMC来比较输出。</p>
</div>
<div id="r-inla" class="section level1">
<h1>使用R-INLA</h1>
<p>R-INLA依赖于独立的C库（GMRF），因此不在CRAN上，但可以从<a href="http://www.r-inla.org" class="uri">http://www.r-inla.org</a>获取所有信息。</p>
<p>我将通过两个使用rjags和INLA使用R-INLA的MCMC的简单例子</p>
<div class="section level2">
<h2>1.简单的线性回归</h2>
<p><span class="math display">\[E(y_i|x_i) = \alpha + \beta x_i\]</span></p>
<p><strong>R中的模拟数据</strong></p>
<pre><code>N = 100 #500, 5000, 25000, 100000  
x = rnorm(N, mean=6,sd=2)
y = rnorm(N, mean=x,sd=1) 
data = list(x=x,y=y,N=N) </code></pre>
<p><strong>JAGS代码</strong></p>
<pre><code>model = function() {  
  for(i in 1:N) {
    y[i] ~ dnorm(mu[i],tau)
    mu[i] &lt;- alpha + beta*x[i] 
  }
  alpha  ~ dnorm(0,0.001)
  beta  ~ dnorm(0,0.001) 
  tau ~ dgamma(0.01,0.01) 
}  
params = c(&quot;alpha&quot;,&quot;beta&quot;,&quot;tau&quot;,&quot;mu&quot;) 
jags(data=data,param=params,n.chains=3,n.iter=50000, n.burnin=5000, model.file=model)  </code></pre>
<p><strong>INLA代码</strong></p>
<pre><code>inla(y~x, family = c(&quot;gaussian&quot;), data = data, control.predictor=list(link=1)) </code></pre>
<p>INLA生成一个后验密度，而不是像MCMC这样的模拟经验分布。您可以在下边的图中看到这三个参数与JAGS（直方图）和INLA（密度曲线）的分布有多相似。</p>
<p>{{&lt; figure src=“/img/inla-posteriors.png” title=“inla-posteriors” &gt;}}</p>
<p>在这里很容易，但有时很难知道默认的INLA先验，他们可以发挥很大的作用，特别是当数据集很小时。如果您在比较MCMC和INLA之前，在假设INLA近似值失败之前，我强烈建议您确认使用的先验值是否相同。有时，INLA定义了逻辑尺度上的先验（例如）。</p>
<p>即使是这样一个简单的例子，随着样本量的增加，R-INLA和JAGS的节省时间显着。</p>
</div>
<div id="iidglm" class="section level2">
<h2>2.具有iid随机效应的泊松GLM</h2>
<p><span class="math display">\[E(y_i|x_i) = poisson(\mu_i) \]</span> <span class="math display">\[log(\mu_i) = \alpha + \beta x_i + \nu_i\]</span> <span class="math display">\[\nu_i \sim N(0,\tau_\nu)\]</span></p>
<p><strong>模拟的数据</strong></p>
<pre><code>N = 100 # 500, 5000, 25000, 100000 
x = rnorm(N, mean=5,sd=1) 
nu = rnorm(N,0,0.1)
mu = exp(1 + 0.5*x + nu) 
y = rpois(N,mu)</code></pre>
<p><strong>JAGS</strong></p>
<pre><code>model = function() {  
  for(i in 1:N) {
    y[i] ~ dpois(mu[i]) 
    log(mu[i]) &lt;- alpha + beta*x[i] + nu[i]
    nu[i] ~ dnorm(0,tau.nu) 
  }
  alpha  ~ dnorm(0,0.001)
  beta  ~ dnorm(0,0.001) 
  tau.nu ~ dgamma(0.01,0.01) 
}  
params = c(&quot;alpha&quot;,&quot;beta&quot;,&quot;tau.nu&quot;,&quot;mu&quot;) 
jags(data=data,param=params,n.chains=3,n.iter=50000, n.burnin=5000, model.file=model)   </code></pre>
<p><strong>INLA代码</strong></p>
<pre><code>nu = 1:N 
inla(y ~ x + f(nu,model=&quot;iid&quot;), family = c(&quot;poisson&quot;), 
           data = data, control.predictor=list(link=1)) </code></pre>
<p>我没有在这里显示分布，但参数估计是可比的。节省的时间真的再次显着。在我的博士学位中，我提出了一个多变量（多重结果）的预测模型，并且没有INLA方法，对于我正在研究的公共卫生应用来说，它不是一个实用的模型，因为模型必须适合每个模型天。我也会在这里引用我关于这个模型的论文。尽管我现在所做的事情往往不那么复杂，但我仍然喜欢使用INLA来进行很多贝叶斯工作。</p>
<p>除了更直观的理论之外，我更喜欢关于MCMC代码的唯一的东西是BUGS/JAGS和INLA的语法。虽然INLA看起来不错，因为它与R的glm功能相似，但有时前辈对我的喜好太隐蔽了。我发现BUGS代码真正以一种对教学和学习有益的方式来突出模型的层次结构。</p>
<p>你在应用研究/工作中使用贝叶斯模型吗？你写自己的MCMC，和/或使用Bug/Jags/Stan，和/或你是否尝试过INLA？我很乐意在评论中听到任何人的思想和经验。</p>
</div>
</div>
<div class="section level1">
<h1>参考</h1>
</div>

      </div>

      


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="../../tags/stats">stats</a>
  
</div>



    </div>
  </div>

</article>



<div class="article-container article-widget">
  <div class="hr-light"></div>
  <h3>Related</h3>
  <ul>
    
    <li><a href="../../project/stats_r/">统计&amp;编程</a></li>
    
    <li><a href="../../post/2018-01-02-%E5%88%B0%E5%BA%95%E6%98%AF%E5%9B%BA%E5%AE%9A%E8%BF%98%E6%98%AF%E9%9A%8F%E6%9C%BA/">到底是固定还是随机？</a></li>
    
  </ul>
</div>




<div class="article-container">
  
<section id="comments">
  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "dong" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 Dong &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//dong.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="../../js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

